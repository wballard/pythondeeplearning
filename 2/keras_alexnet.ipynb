{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up an AlexNet in Keras. This is a relatively early network design, but goes quite deep compared to a multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the CIFAR images, normalize the images on all color channels 0-1, and one hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10 # 10 output digits\n",
    "batch_size = 128 # mini batch\n",
    "epochs = 10 # total training loops\n",
    "learning_rate = 0.01 # amount we update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images = np.expand_dims(train_images / np.max(train_images), -1)\n",
    "test_images = np.expand_dims(test_images / np.max(test_images), -1)\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_outputs)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for our actual model. AlexNet was one of the original deep models that led to the resurgence of neural network techniques in machine learning. It had several innovations -- it was quite deep -- and it combined convolution with attenation -- merging together pixes with convolution, but adding more neural network depth.\n",
    "\n",
    "We'll create these networks without special techniques like dropout or batch normalization to get a simplified view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_kernels = [(11, 11), (5, 5), (3, 3), (3, 3), (3, 3)]\n",
    "convolution_filters = [96, 256, 512, 1024, 1024]\n",
    "convolutional_pooling = (2, 2)\n",
    "dense_units = [4096, 4096]\n",
    "image_shape = train_images.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a few loops to stack up the deep layers. This lets you get a sense that making a deep network is just about layering.\n",
    "\n",
    "We'll put in one placeholder layer to contain the image shape extracted frome the training data.\n",
    "\n",
    "Note the use of `same` padding. This actually will pad the images. We need to do this here so that the input image is in fact big enough to 'divide' this many times. You'll see we in the final convolution we end up with a very small x and y dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 4096)        4198400   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 37,008,266\n",
      "Trainable params: 37,008,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alexnet = Sequential()\n",
    "alexnet.add(Reshape(image_shape[:-1], input_shape=image_shape))\n",
    "for kernel, filters in zip(convolution_kernels, convolution_filters):\n",
    "    alexnet.add(Conv2D(filters, kernel, activation='relu', padding='same'))\n",
    "    alexnet.add(MaxPooling2D(convolutional_pooling, padding='same'))\n",
    "for units in dense_units:\n",
    "    alexnet.add(Dense(units, activation='relu'))\n",
    "alexnet.add(Flatten())\n",
    "alexnet.add(Dense(num_outputs, activation='softmax'))\n",
    "alexnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as always, learning is done with an optimizer and a loss function, learning a classifier with categorical cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "loss = keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, keep in mind this is starting to be a pretty big model. If you train this on a CPU, it is *possible*, but it is going to take a very long time. I'm running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s 442us/step - loss: 2.2970 - acc: 0.1295 - val_loss: 2.2837 - val_acc: 0.1030\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 2.1837 - acc: 0.1849 - val_loss: 2.0200 - val_acc: 0.2650\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 2.0013 - acc: 0.2668 - val_loss: 1.9353 - val_acc: 0.3042\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.9060 - acc: 0.3111 - val_loss: 1.8214 - val_acc: 0.3516\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 1.8126 - acc: 0.3464 - val_loss: 1.9184 - val_acc: 0.3015\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.7209 - acc: 0.3807 - val_loss: 1.6441 - val_acc: 0.4062\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.6388 - acc: 0.4090 - val_loss: 1.6480 - val_acc: 0.4094\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.5684 - acc: 0.4366 - val_loss: 1.5389 - val_acc: 0.4465\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s 282us/step - loss: 1.5107 - acc: 0.4584 - val_loss: 1.4651 - val_acc: 0.4820\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s 284us/step - loss: 1.4567 - acc: 0.4779 - val_loss: 1.4514 - val_acc: 0.4831\n"
     ]
    }
   ],
   "source": [
    "alexnet.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = alexnet.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this isn't mind boggling accurate, but it is a very complex problem to recognize open images. We can see this model kept learning on each epoch, and didn't appear to overfit. You should as an experiment, increase the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
